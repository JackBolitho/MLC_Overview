{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "624e9f9a-1969-4947-889f-57adffa8183d",
   "metadata": {},
   "source": [
    "## This script is a modified version of [https://github.com/mlc-ai/notebooks/blob/main/4_Build_End_to_End_Model.ipynb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "07503c9a-ed1e-4b5b-bdc4-fec9621d4ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm.script import tir as T, relax as R\n",
    "import numpy as np\n",
    "from tvm import relax\n",
    "# This is needed for deferring annotation parsing in TVMScript\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aba8c081-a3a8-4e8a-bbf3-aa1f7129bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "#get the test data with pytorch\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "img, label = next(iter(test_loader))\n",
    "img = img.reshape(1, 28, 28).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9acd7102-d6c6-4e6f-98b1-15cba82e7793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Sandal\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "print(\"Class:\", class_names[label[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f63b19a8-ce1d-4737-9402-7d9c3b79e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_mlp(data, w0, b0, w1, b1):\n",
    "    lv0 = data @ w0.T + b0\n",
    "    lv1 = np.maximum(lv0, 0)\n",
    "    lv2 = lv1 @ w1.T + b1\n",
    "    return lv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548403aa-be42-4dd5-8445-4ecf3b77370c",
   "metadata": {},
   "source": [
    "Weights and biases: [https://github.com/mlc-ai/web-data/blob/main/models/fasionmnist_mlp_params.pkl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5a520773-79bc-4e98-9d25-ced644c70065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-15.938702 -22.90845  -18.182028 -22.514837 -19.086128  20.452694\n",
      "  -16.290257 -19.265121 -12.368678  -8.49461 ]]\n",
      "[5]\n",
      "Numpy-MLP Prediction: Sandal\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "mlp_params = pkl.load(open(\"./parameters/fasionmnist_mlp_params.pkl\", \"rb\"))\n",
    "res = numpy_mlp(img.reshape(1, 784),\n",
    "                mlp_params[\"w0\"],\n",
    "                mlp_params[\"b0\"],\n",
    "                mlp_params[\"w1\"],\n",
    "                mlp_params[\"b1\"])\n",
    "print(res)\n",
    "pred_kind = res.argmax(axis=1)\n",
    "print(pred_kind)\n",
    "print(\"Numpy-MLP Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "13b02d96-15ad-4a09-bb9d-7c9b8ff46d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level Numpy MLP Prediction: Sandal\n"
     ]
    }
   ],
   "source": [
    "#these are low level numpy implementations of each linear layer\n",
    "def lnumpy_linear0(X: np.ndarray, W: np.ndarray, B: np.ndarray, Z: np.ndarray):\n",
    "    Y = np.empty((1, 128), dtype=\"float32\")\n",
    "    for i in range(1):\n",
    "        for j in range(128):\n",
    "            for k in range(784):\n",
    "                if k == 0:\n",
    "                    Y[i, j] = 0\n",
    "                Y[i, j] = Y[i, j] + X[i, k] * W[j, k]\n",
    "\n",
    "    for i in range(1):\n",
    "        for j in range(128):\n",
    "            Z[i, j] = Y[i, j] + B[j]\n",
    "\n",
    "\n",
    "def lnumpy_relu0(X: np.ndarray, Y: np.ndarray):\n",
    "     for i in range(1):\n",
    "        for j in range(128):\n",
    "            Y[i, j] = np.maximum(X[i, j], 0)\n",
    "\n",
    "def lnumpy_linear1(X: np.ndarray, W: np.ndarray, B: np.ndarray, Z: np.ndarray):\n",
    "    Y = np.empty((1, 10), dtype=\"float32\")\n",
    "    for i in range(1):\n",
    "        for j in range(10):\n",
    "            for k in range(128):\n",
    "                if k == 0:\n",
    "                    Y[i, j] = 0\n",
    "                Y[i, j] = Y[i, j] + X[i, k] * W[j, k]\n",
    "\n",
    "    for i in range(1):\n",
    "        for j in range(10):\n",
    "            Z[i, j] = Y[i, j] + B[j]\n",
    "\n",
    "def lnumpy_mlp(data, w0, b0, w1, b1):\n",
    "    lv0 = np.empty((1, 128), dtype=\"float32\")\n",
    "    lnumpy_linear0(data, w0, b0, lv0)\n",
    "\n",
    "    lv1 = np.empty((1, 128), dtype=\"float32\")\n",
    "    lnumpy_relu0(lv0, lv1)\n",
    "\n",
    "    out = np.empty((1, 10), dtype=\"float32\")\n",
    "    lnumpy_linear1(lv1, w1, b1, out)\n",
    "    return out\n",
    "\n",
    "result =lnumpy_mlp(\n",
    "    img.reshape(1, 784),\n",
    "    mlp_params[\"w0\"],\n",
    "    mlp_params[\"b0\"],\n",
    "    mlp_params[\"w1\"],\n",
    "    mlp_params[\"b1\"])\n",
    "\n",
    "pred_kind = result.argmax(axis=1)\n",
    "print(\"Low-level Numpy MLP Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9a613e73-5276-4798-9097-64843c78b95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-level Numpy with callTIR Prediction: Sandal\n"
     ]
    }
   ],
   "source": [
    "def lnumpy_call_tir(prim_func, inputs, shape, dtype):\n",
    "    res = np.empty(shape, dtype=dtype)\n",
    "    prim_func(*inputs, res)\n",
    "    return res\n",
    "\n",
    "#this is an example of a computational graph abstraction\n",
    "def lnumpy_mlp_with_call_tir(data, w0, b0, w1, b1):\n",
    "    lv0 = lnumpy_call_tir(lnumpy_linear0, (data, w0, b0), (1, 128), dtype=\"float32\")\n",
    "    lv1 = lnumpy_call_tir(lnumpy_relu0, (lv0, ), (1, 128), dtype=\"float32\")\n",
    "    out = lnumpy_call_tir(lnumpy_linear1, (lv1, w1, b1), (1, 10), dtype=\"float32\")\n",
    "    return out\n",
    "\n",
    "result = lnumpy_mlp_with_call_tir(\n",
    "    img.reshape(1, 784),\n",
    "    mlp_params[\"w0\"],\n",
    "    mlp_params[\"b0\"],\n",
    "    mlp_params[\"w1\"],\n",
    "    mlp_params[\"b1\"])\n",
    "\n",
    "pred_kind = np.argmax(result, axis=1)\n",
    "print(\"Low-level Numpy with callTIR Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ccf0030c-a199-4c28-960d-3e54a34faa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyModule:\n",
    "    @T.prim_func\n",
    "    def relu0(X: T.Buffer((1, 128), \"float32\"),\n",
    "              Y: T.Buffer((1, 128), \"float32\")):\n",
    "        # function attr dict\n",
    "        T.func_attr({\"global_symbol\": \"relu0\", \"tir.noalias\": True})\n",
    "        for i, j in T.grid(1, 128):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Y[vi, vj] = T.max(X[vi, vj], T.float32(0))\n",
    "\n",
    "    @T.prim_func\n",
    "    def linear0(X: T.Buffer((1, 784), \"float32\"),\n",
    "                W: T.Buffer((128, 784), \"float32\"),\n",
    "                B: T.Buffer((128,), \"float32\"),\n",
    "                Z: T.Buffer((1, 128), \"float32\")):\n",
    "        T.func_attr({\"global_symbol\": \"linear0\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer((1, 128), \"float32\")\n",
    "        for i, j, k in T.grid(1, 128, 784):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
    "                with T.init():\n",
    "                    Y[vi, vj] = T.float32(0)\n",
    "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
    "\n",
    "        for i, j in T.grid(1, 128):\n",
    "            with T.block(\"Z\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Z[vi, vj] =  Y[vi, vj] + B[vj]\n",
    "\n",
    "    @T.prim_func\n",
    "    def linear1(X: T.Buffer((1, 128), \"float32\"),\n",
    "                W: T.Buffer((10, 128), \"float32\"),\n",
    "                B: T.Buffer((10,), \"float32\"),\n",
    "                Z: T.Buffer((1, 10), \"float32\")):\n",
    "        T.func_attr({\"global_symbol\": \"linear1\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer((1, 10), \"float32\")\n",
    "        for i, j, k in T.grid(1, 10, 128):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
    "                with T.init():\n",
    "                    Y[vi, vj] = T.float32(0)\n",
    "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
    "\n",
    "        for i, j in T.grid(1, 10):\n",
    "            with T.block(\"Z\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Z[vi, vj] = Y[vi, vj] + B[vj]\n",
    "\n",
    "\n",
    "    @R.function #This tag is part of the relax from tvm, which provides high level neural network executions. \n",
    "                #This tag means that this function creates PackedFunc from primitive functions\n",
    "    def main(x: R.Tensor((1, 784), \"float32\"),\n",
    "             w0: R.Tensor((128, 784), \"float32\"),\n",
    "             b0: R.Tensor((128,), \"float32\"),\n",
    "             w1: R.Tensor((10, 128), \"float32\"),\n",
    "             b1: R.Tensor((10,), \"float32\")):\n",
    "\n",
    "        #within the dataflow block, all executions are to be represented as nodes in a computational graph\n",
    "        with R.dataflow():\n",
    "            cls = MyModule\n",
    "\n",
    "            #each call_tir can correspond to a node on a computational graph representing the whole neural network,\n",
    "            #which passes parameters to the first layer, then to a relu, then to the final layer\n",
    "\n",
    "            #we expect all computational graph nodes to be \"side-effect free\", which means that they do not allocate memory\n",
    "            #all memory allocation in these graph representations should be performed seperate from the primitive tensor functions,\n",
    "            #which means that we pass \"handles\" (pointers) of pre-allocated memory for function inputs AND outputs\n",
    "\n",
    "            #side-effect free functions allows said functions to be modular and to be paralellized; we minimize memory dependencies\n",
    "\n",
    "            #relax.call_tir takes the name of the function from the module (MyModule.linear0), the list of inputs to the \n",
    "            #layer (the input tensor, the first layer weights and biases, the shape of the output (1, 128), and the data type of the \n",
    "            #ouput tensor\n",
    "            lv0 = R.call_tir(cls.linear0, (x, w0, b0), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
    "            lv1 = R.call_tir(cls.relu0, (lv0,), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
    "            out = R.call_tir(cls.linear1, (lv1, w1, b1), out_sinfo=R.Tensor((1, 10), dtype=\"float32\"))\n",
    "\n",
    "            #relax output is the only output from the dataflow block\n",
    "            R.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4f9a9968-6ed2-4b3b-9e00-f719cd54f1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.relax.vm_build.Executable"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modules using relax must be built with relax.build, whereas ones which only use tvm can be built with tvm.build,\n",
    "#syntax is the same for both \n",
    "ex = relax.build(MyModule, target=\"llvm\")\n",
    "type(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4f03f035-81d5-4d42-9c9a-d42c2157ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tells us that all intermediate computations are to be performed by cpu, the program is run on the virtual machine\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8073f965-3f3a-401b-9105-eaed36f32a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#casts everything to tvm compatible types\n",
    "data_nd = tvm.nd.array(img.reshape(1, 784))\n",
    "nd_params = {k: tvm.nd.array(v) for k, v in mlp_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a6adc14d-2b73-4185-8781-bc46fd87114c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.nd.NDArray shape=(1, 10), cpu(0)>\n",
       "array([[-15.938702, -22.908457, -18.182026, -22.514837, -19.086128,\n",
       "         20.452694, -16.290257, -19.265118, -12.368677,  -8.494609]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd_res = vm[\"main\"](data_nd,\n",
    "                    nd_params[\"w0\"],\n",
    "                    nd_params[\"b0\"],\n",
    "                    nd_params[\"w1\"],\n",
    "                    nd_params[\"b1\"])\n",
    "nd_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3499311c-f56c-4073-89c7-4d9e92dfc8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModule Prediction: Sandal\n"
     ]
    }
   ],
   "source": [
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MyModule Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "df714c35-dd97-457c-b180-6a1bfcb39d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyModuleWithExternCall:\n",
    "    @R.function\n",
    "    def main(x: R.Tensor((1, 784), \"float32\"),\n",
    "             w0: R.Tensor((128, 784), \"float32\"),\n",
    "             b0: R.Tensor((128,), \"float32\"),\n",
    "             w1: R.Tensor((10, 128), \"float32\"),\n",
    "             b1: R.Tensor((10,), \"float32\")):\n",
    "        # block 0\n",
    "        with R.dataflow():\n",
    "\n",
    "            #instead of calling tensor functions we created, this is using a library\n",
    "            #upon runtime, the compiler expects to find a function labeled as whatever the given name is\n",
    "            lv0 = R.call_dps_packed(\"env.linear\", (x, w0, b0), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
    "            lv1 = R.call_dps_packed(\"env.relu\", (lv0,), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
    "            out = R.call_dps_packed(\"env.linear\", (lv1, w1, b1), out_sinfo=R.Tensor((1, 10), dtype=\"float32\"))\n",
    "            R.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "07297967-ccf5-4a71-821c-a5ee2582bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the way the compiler resolves the labels given by the user when calling relax.call_dps_packed is by registering each\n",
    "#function, in which \n",
    "@tvm.register_func(\"env.linear\", override=True)\n",
    "def torch_linear(x: tvm.nd.NDArray,\n",
    "                 w: tvm.nd.NDArray,\n",
    "                 b: tvm.nd.NDArray,\n",
    "                 out: tvm.nd.NDArray):\n",
    "\n",
    "    #torch.from_dlpack is a way of exchanging information without creating copies, both the tvm array and the torch array\n",
    "    #point to the same piece of memory\n",
    "    x_torch = torch.from_dlpack(x)\n",
    "    w_torch = torch.from_dlpack(w)\n",
    "    b_torch = torch.from_dlpack(b)\n",
    "    out_torch = torch.from_dlpack(out)\n",
    "    torch.mm(x_torch, w_torch.T, out=out_torch)\n",
    "    torch.add(out_torch, b_torch, out=out_torch)\n",
    "\n",
    "@tvm.register_func(\"env.relu\", override=True)\n",
    "def lnumpy_relu(x: tvm.nd.NDArray,\n",
    "                out: tvm.nd.NDArray):\n",
    "    x_torch = torch.from_dlpack(x)\n",
    "    out_torch = torch.from_dlpack(out)\n",
    "    torch.maximum(x_torch, torch.Tensor([0.0]), out=out_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5f4edb08-b434-4633-b5a5-074e3fa541ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = relax.build(MyModuleWithExternCall, target=\"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "41717e49-0d4d-44e7-bde3-58fc10c5f944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModuleWithExternCall Prediction: Sandal\n"
     ]
    }
   ],
   "source": [
    "nd_res = vm[\"main\"](data_nd,\n",
    "                    nd_params[\"w0\"],\n",
    "                    nd_params[\"b0\"],\n",
    "                    nd_params[\"w1\"],\n",
    "                    nd_params[\"b1\"])\n",
    "\n",
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MyModuleWithExternCall Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6daa7690-2318-4b72-909b-1de1390a0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyModuleMixture:\n",
    "    @T.prim_func\n",
    "    def linear0(X: T.Buffer((1, 784), \"float32\"),\n",
    "                W: T.Buffer((128, 784), \"float32\"),\n",
    "                B: T.Buffer((128,), \"float32\"),\n",
    "                Z: T.Buffer((1, 128), \"float32\")):\n",
    "        T.func_attr({\"global_symbol\": \"linear0\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer((1, 128), \"float32\")\n",
    "        for i, j, k in T.grid(1, 128, 784):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
    "                with T.init():\n",
    "                    Y[vi, vj] = T.float32(0)\n",
    "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
    "\n",
    "        for i, j in T.grid(1, 128):\n",
    "            with T.block(\"Z\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                Z[vi, vj] =  Y[vi, vj] + B[vj]\n",
    "                \n",
    "    #this function uses a mixture of library calls and tvm script implementations\n",
    "    @R.function\n",
    "    def main(x: R.Tensor((1, 784), \"float32\"),\n",
    "             w0: R.Tensor((128, 784), \"float32\"),\n",
    "             b0: R.Tensor((128,), \"float32\"),\n",
    "             w1: R.Tensor((10, 128), \"float32\"),\n",
    "             b1: R.Tensor((10,), \"float32\")):\n",
    "        with R.dataflow():\n",
    "            cls = MyModuleMixture\n",
    "            lv0 = R.call_tir(cls.linear0, (x, w0, b0), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
    "            lv1 = R.call_dps_packed(\"env.relu\", (lv0,), out_sinfo=R.Tensor((1, 128), dtype=\"float32\"))\n",
    "            out = R.call_dps_packed(\"env.linear\", (lv1, w1, b1), out_sinfo=R.Tensor((1, 10), dtype=\"float32\"))\n",
    "            R.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9f6d94f8-cb9c-4095-ab4a-f463158e534b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModuleMixture Prediction: Sandal\n"
     ]
    }
   ],
   "source": [
    "ex = relax.build(MyModuleMixture, target=\"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "\n",
    "nd_res = vm[\"main\"](data_nd,\n",
    "                    nd_params[\"w0\"],\n",
    "                    nd_params[\"b0\"],\n",
    "                    nd_params[\"w1\"],\n",
    "                    nd_params[\"b1\"])\n",
    "\n",
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MyModuleMixture Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9df6591e-ba56-4f4d-b857-3a75144fb345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">linear0</span>(X: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), W: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">784</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), Z: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        Y <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>))\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">784</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;Y&quot;</span>):\n",
       "                vi, vj, vk <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(X[vi, vk], W[vj, vk])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(Y[vi, vj])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>)\n",
       "                Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">+</span> X[vi, vk] <span style=\"color: #AA22FF; font-weight: bold\">*</span> W[vj, vk]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;Z&quot;</span>):\n",
       "                vi, vj <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i, j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(Y[vi, vj], B[vj])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(Z[vi, vj])\n",
       "                Z[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">+</span> B[vj]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv0 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>linear0, (x, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_dps_packed(<span style=\"color: #BA2121\">&quot;env.relu&quot;</span>, (lv0,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            out <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_dps_packed(<span style=\"color: #BA2121\">&quot;env.linear&quot;</span>, (lv1, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(out)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> out\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#binding parameters to calls of the function\n",
    "MyModuleWithParams = relax.transform.BindParams(\"main\", nd_params)(MyModuleMixture)\n",
    "MyModuleWithParams.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d0c85eb0-9257-4e25-b3fc-e8a9931fefeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModuleWithParams Prediction: Sandal\n"
     ]
    }
   ],
   "source": [
    "ex = relax.build(MyModuleWithParams, target=\"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "\n",
    "nd_res = vm[\"main\"](data_nd)\n",
    "\n",
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MyModuleWithParams Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addc0c6f-9b18-4019-b185-4d5e846492f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
