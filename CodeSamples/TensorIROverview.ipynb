{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "bc4d5338-723c-415e-a647-faad4d2c570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm.script import tir #stands for tensor intermediate representation\n",
    "from tvm.ir.module import IRModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "e24ee5aa-6893-4a74-a9a0-bb33c9405235",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module #this tells us that this class is an ir_module\n",
    "class TensorModule():\n",
    "\n",
    "    @tir.prim_func #this tells us that this function is a primitive function\n",
    "    def TensorFunction(array: tir.Buffer((4), \"float32\")) : #a buffer is a tir type representing a tensor of a designated data type and size\n",
    "\n",
    "        #provides metadata about the function\n",
    "        #the global symbol is the name that identifies the function, default is function name\n",
    "        #noalias states whether or not the function has aliasing over memory buffers\n",
    "        tir.func_attr({\"global_symbol\": \"TensorFunction\", \"tir.noalias\": True}) \n",
    "\n",
    "        #increments each element in the buffer by 1\n",
    "        for i in range(4) :\n",
    "            array[i] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "7e60740e-8a6e-4ae2-8e81-d37a4d3ca6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a whole module must be built before a function can be called, and this build target is the low level virtual machine\n",
    "builtModule = tvm.build(TensorModule, target=\"llvm\")\n",
    "\n",
    "#this gets a specific packed function from the module, which can be run\n",
    "functionToRun = builtModule[\"TensorFunction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "1b65c549-dc0d-44ad-881b-9c3939430c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "#create a buffer \n",
    "array = tvm.nd.array(np.array([1,2,3,4], dtype=\"f\"))\n",
    "\n",
    "#pass array in, usually we only pass \"handles\" (pointers) of buffers to a built function, since memory allocation is left to the OS\n",
    "functionToRun(array)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "7d3b29e9-ad80-4af3-9f6c-255a0cc371ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class SuperTensorModule():\n",
    "\n",
    "    @tir.prim_func\n",
    "    def matmul(A: tir.Buffer((5,5), \"float32\"), \n",
    "               B: tir.Buffer((5,5), \"float32\"), \n",
    "               C: tir.Buffer((5,5), \"float32\"))  :\n",
    "        tir.func_attr({\"global_symbol\": \"matmul\", \"tir.noalias\": True})\n",
    "\n",
    "        #shorthand for nested loops\n",
    "        for i, j, k in tir.grid(5,5,5) :\n",
    "            with tir.block(\"C\") : #block is basic unit of tensorIR computation, needed for axis mapping\n",
    "                vi, vj, vk = tir.axis.remap(\"SSR\", [i, j, k]) #remaps indicies i, j, and k to spatial, spatial, and reduce axes respectively\n",
    "                with tir.init() : #runs when the block is first instatiated\n",
    "                    C[vi, vj] = 0 \n",
    "                C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vk, vj] #compute each element of matrix\n",
    "\n",
    "    @tir.prim_func\n",
    "    def relu(A: tir.Buffer((5,5), \"float32\")) :\n",
    "        tir.func_attr({\"global_symbol\": \"relu\", \"tir.noalias\": True})\n",
    "\n",
    "        for i, j in tir.grid(5,5) :\n",
    "            with tir.block(\"A\") :\n",
    "                vi, vj = tir.axis.remap(\"SS\", [i, j])\n",
    "                if(A[vi, vj] < 0) :\n",
    "                    A[vi, vj] = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "815cb662-fdbd-4949-bf2f-db00c32d7106",
   "metadata": {},
   "outputs": [],
   "source": [
    "builtModule = tvm.build(SuperTensorModule, target=\"llvm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "cd07d04b-da43-457a-ab58-194b50686257",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tvm.nd.array(np.arange(25, dtype=\"f\").reshape((5,5)))\n",
    "B = tvm.nd.array(np.arange(25, dtype=\"f\").reshape((5,5)))\n",
    "C = tvm.nd.empty((5,5))\n",
    "D = tvm.nd.array(np.arange(-12, 13, dtype=\"f\").reshape(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "7065d159-9d64-4d19-b726-becbbc48c8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 150.  160.  170.  180.  190.]\n",
      " [ 400.  435.  470.  505.  540.]\n",
      " [ 650.  710.  770.  830.  890.]\n",
      " [ 900.  985. 1070. 1155. 1240.]\n",
      " [1150. 1260. 1370. 1480. 1590.]]\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  2.]\n",
      " [ 3.  4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11. 12.]]\n"
     ]
    }
   ],
   "source": [
    "builtModule[\"matmul\"](A,B,C)\n",
    "print(C)\n",
    "builtModule[\"relu\"](D)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "f4b8d8cd-9f4c-4740-923e-b88f23cdd0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def matmul(A: T.Buffer((5, 5), \"float32\"), B: T.Buffer((5, 5), \"float32\"), C: T.Buffer((5, 5), \"float32\")):\n",
      "        T.func_attr({\"tir.noalias\": T.bool(True)})\n",
      "        # with T.block(\"root\"):\n",
      "        for i, j, k in T.grid(5, 5, 5):\n",
      "            with T.block(\"C\"):\n",
      "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
      "                T.reads(A[vi, vk], B[vk, vj])\n",
      "                T.writes(C[vi, vj])\n",
      "                with T.init():\n",
      "                    C[vi, vj] = T.float32(0.0)\n",
      "                C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vk, vj]\n",
      "\n",
      "    @T.prim_func\n",
      "    def relu(A: T.Buffer((5, 5), \"float32\")):\n",
      "        T.func_attr({\"tir.noalias\": T.bool(True)})\n",
      "        # with T.block(\"root\"):\n",
      "        for i, j in T.grid(5, 5):\n",
      "            with T.block(\"A\"):\n",
      "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
      "                T.reads(A[vi, vj])\n",
      "                T.writes(A[vi, vj])\n",
      "                if A[vi, vj] < T.float32(0.0):\n",
      "                    A[vi, vj] = T.float32(0.0)\n"
     ]
    }
   ],
   "source": [
    "#print out the tensor module script\n",
    "print(SuperTensorModule.script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "cad003c0-bbae-4f60-9c35-78a1e7ce5d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a schedule, which is a wrapper for your module that allows for tensor function transformations\n",
    "schedule = tvm.tir.Schedule(SuperTensorModule)\n",
    "\n",
    "#get a block from the module, our basic unit of computation, which we can transform\n",
    "block_C = schedule.get_block(\"C\", func_name=\"matmul\")\n",
    "\n",
    "#gets the iterators of the block C\n",
    "i, j, k = schedule.get_loops(block_C)\n",
    "\n",
    "#split the iterator j into j0 and j1, to reduce cache stride\n",
    "j0, j1 = schedule.split(j, factors=[None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "22461276-bfde-415a-827a-0aabee3e3feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def matmul(A: T.Buffer((5, 5), \"float32\"), B: T.Buffer((5, 5), \"float32\"), C: T.Buffer((5, 5), \"float32\")):\n",
      "        T.func_attr({\"tir.noalias\": T.bool(True)})\n",
      "        # with T.block(\"root\"):\n",
      "        for i, j_0, j_1, k in T.grid(5, 3, 2, 5):\n",
      "            with T.block(\"C\"):\n",
      "                vi = T.axis.spatial(5, i)\n",
      "                vj = T.axis.spatial(5, j_0 * 2 + j_1)\n",
      "                vk = T.axis.reduce(5, k)\n",
      "                T.where(j_0 * 2 + j_1 < 5)\n",
      "                T.reads(A[vi, vk], B[vk, vj])\n",
      "                T.writes(C[vi, vj])\n",
      "                with T.init():\n",
      "                    C[vi, vj] = T.float32(0.0)\n",
      "                C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vk, vj]\n",
      "\n",
      "    @T.prim_func\n",
      "    def relu(A: T.Buffer((5, 5), \"float32\")):\n",
      "        T.func_attr({\"tir.noalias\": T.bool(True)})\n",
      "        # with T.block(\"root\"):\n",
      "        for i, j in T.grid(5, 5):\n",
      "            with T.block(\"A\"):\n",
      "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
      "                T.reads(A[vi, vj])\n",
      "                T.writes(A[vi, vj])\n",
      "                if A[vi, vj] < T.float32(0.0):\n",
      "                    A[vi, vj] = T.float32(0.0)\n"
     ]
    }
   ],
   "source": [
    "print(schedule.mod.script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "b01f72c2-d4d1-422a-ad9e-5db3daea31ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def matmul(A: T.Buffer((5, 5), \"float32\"), B: T.Buffer((5, 5), \"float32\"), C: T.Buffer((5, 5), \"float32\")):\n",
      "        T.func_attr({\"tir.noalias\": T.bool(True)})\n",
      "        # with T.block(\"root\"):\n",
      "        for i, j_0, k, j_1 in T.grid(5, 3, 5, 2):\n",
      "            with T.block(\"C\"):\n",
      "                vi = T.axis.spatial(5, i)\n",
      "                vj = T.axis.spatial(5, j_0 * 2 + j_1)\n",
      "                vk = T.axis.reduce(5, k)\n",
      "                T.where(j_0 * 2 + j_1 < 5)\n",
      "                T.reads(A[vi, vk], B[vk, vj])\n",
      "                T.writes(C[vi, vj])\n",
      "                with T.init():\n",
      "                    C[vi, vj] = T.float32(0.0)\n",
      "                C[vi, vj] = C[vi, vj] + A[vi, vk] * B[vk, vj]\n",
      "\n",
      "    @T.prim_func\n",
      "    def relu(A: T.Buffer((5, 5), \"float32\")):\n",
      "        T.func_attr({\"tir.noalias\": T.bool(True)})\n",
      "        # with T.block(\"root\"):\n",
      "        for i, j in T.grid(5, 5):\n",
      "            with T.block(\"A\"):\n",
      "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
      "                T.reads(A[vi, vj])\n",
      "                T.writes(A[vi, vj])\n",
      "                if A[vi, vj] < T.float32(0.0):\n",
      "                    A[vi, vj] = T.float32(0.0)\n"
     ]
    }
   ],
   "source": [
    "#alters the order of the loops, once again for caching purposes\n",
    "schedule.reorder(i, j0, k, j1)\n",
    "print(schedule.mod.script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "d9a186eb-b1bd-48ec-b5ef-733b3cec0444",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class TensorModuleII():\n",
    "    @tir.prim_func\n",
    "    def mm_relu(A: tir.Buffer((5,5), \"float32\"), \n",
    "                B: tir.Buffer((5,5), \"float32\"), \n",
    "                X: tir.Buffer((5,5), \"float32\"))  :\n",
    "        tir.func_attr({\"global_symbol\": \"mm_relu\", \"tir.noalias\": True})\n",
    "\n",
    "        #allocates a buffer (array) \n",
    "        Y = tir.alloc_buffer((5,5), \"float32\")\n",
    "        #mm part\n",
    "        for i, j, k in tir.grid(5,5,5):\n",
    "            with tir.block(\"Y\"):\n",
    "                vi = tir.axis.spatial(5, i) #another way of mapping an index\n",
    "                vj = tir.axis.spatial(5, j)\n",
    "                vk = tir.axis.reduce(5, k) #spatial means indicies are independent, reduce means they take multiple elements and combine them to one (dependencies)\n",
    "                with tir.init():\n",
    "                    Y[vi, vj] = 0\n",
    "                Y[vi, vj] = Y[vi, vj] + A[vi, vk] * B[vk, vj]\n",
    "\n",
    "        #relu part\n",
    "        for i, j in tir.grid(5,5):\n",
    "            with tir.block(\"X\"):\n",
    "                vi = tir.axis.spatial(5,i)\n",
    "                vj = tir.axis.spatial(5,j)\n",
    "                X[vi, vj] = tir.max(Y[vi, vj], tir.float32(0.0))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "12d5d147-e3fb-4cd7-8435-7a4c0d2fd3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def mm_relu(A: T.Buffer((5, 5), \"float32\"), B: T.Buffer((5, 5), \"float32\"), X: T.Buffer((5, 5), \"float32\")):\n",
      "        T.func_attr({\"tir.noalias\": T.bool(True)})\n",
      "        # with T.block(\"root\"):\n",
      "        Y = T.alloc_buffer((5, 5))\n",
      "        for i, j in T.grid(5, 5):\n",
      "            for k in range(5):\n",
      "                with T.block(\"Y\"):\n",
      "                    vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
      "                    T.reads(A[vi, vk], B[vk, vj])\n",
      "                    T.writes(Y[vi, vj])\n",
      "                    with T.init():\n",
      "                        Y[vi, vj] = T.float32(0.0)\n",
      "                    Y[vi, vj] = Y[vi, vj] + A[vi, vk] * B[vk, vj]\n",
      "            with T.block(\"X\"):\n",
      "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
      "                T.reads(Y[vi, vj])\n",
      "                T.writes(X[vi, vj])\n",
      "                X[vi, vj] = T.max(Y[vi, vj], T.float32(0.0))\n"
     ]
    }
   ],
   "source": [
    "newSchedule = tvm.tir.Schedule(TensorModuleII)\n",
    "block_Y = newSchedule.get_block(\"Y\", \"mm_relu\")\n",
    "iY, jY, kY = newSchedule.get_loops(block_Y)\n",
    "block_X = newSchedule.get_block(\"X\", \"mm_relu\")\n",
    "iX, jX = newSchedule.get_loops(block_X)\n",
    "\n",
    "#computes the block X at the index jY\n",
    "newSchedule.reverse_compute_at(block_X, jY)\n",
    "print(newSchedule.mod.script())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
